[["David&nbsp;Chudzicki", "https://plus.google.com/106120852580068301475", "gp-1314975737917", "<p>Is there reason to think that happiness is the kind of thing with a non-arbitrary \u2018zero\u2019 point, so that positive and negative make sense? How would you decide what \u2018zero\u2019 means?\n<br>\n<br>\nAlso: I\u2019m curious about how non-human animals fit into your utilitarianism.</p>", 1314975737], ["Jeff&nbsp;Kaufman", "https://plus.google.com/103013777355236494008", "gp-1314977575913", "<p>The zero point would be at whatever level it was better for a person to have lived than not lived.\n<br>\n<br>\nI don't think non-human animals matter.  I'm not entirely sure of this, so I think it's bad to hurt animals for fun, and I think it's especially bad to harm animals that are more like humans (apes, etc).</p>", 1314977575], ["David&nbsp;Chudzicki", "https://plus.google.com/106120852580068301475", "gp-1314978264947", "<p>Zero point: I'll have to think about this. It's not clear to me how to decide if \"it was better for a person to have lived than not lived.\" (Ask them, I guess?)\n<br>\n<br>\nNon-humans: I find that an odd perspective for a utilitarian. Have you read Peter Singer on the subject? I remember thinking his essay \"All Animals Are Equal\" [1] was pretty convincing. \n<br>\n<br>\n[1] \n<a href=\"http://www.animal-rights-library.com/texts-m/singer02.htm\">http://www.animal-rights-library.com/texts-m/singer02.htm</a></p>", 1314978264], ["Jeff&nbsp;Kaufman", "https://plus.google.com/103013777355236494008", "gp-1314978923172", "<p>@<a href=\"https://plus.google.com/106120852580068301475\">David&nbsp;Chudzicki</a>\n I agree that it's hard to find out how happy a person is, and whether it was better for them to have lived than not lived, but I don't think that means there's not such thing a happiness or a zero point.\n<br>\n<br>\nI've read some peter singer, but not that article.  If it has convinced you, would you mind impersonating it to convince me?</p>", 1314978923], ["David&nbsp;Chudzicki", "https://plus.google.com/106120852580068301475", "gp-1314980865392", "<p>Zero point: Sure it\u2019s fine for something to be hard to know. I just like to think about how (and whether!) it could be known, even in theory. I don\u2019t have a seriously considered epistemology, but I tend to think that if something is, in principle, unknowable, then it\u2019s actually meaningless. Similarly, I think \u201cHow could you know?\u201d is a helpful question in figuring out what something does mean.\n<br>\n<br>\nSinger: Here\u2019s what I remember of the basic idea, which I\u2019ve actually always believed (I may reread to see what else Singer had to say):\n<br>\n<br>\n1. At least some non-human animals clearly experience pain.\n<br>\n2. The pain that non-human animals is bad in the same way and for the same reason that human pain is bad. (They may not be capable of as much pain as humans, but that\u2019s another matter.)</p>", 1314980865], ["Jeff&nbsp;Kaufman", "https://plus.google.com/103013777355236494008", "gp-1314986482562", "<p>@<a href=\"https://plus.google.com/106120852580068301475\">David&nbsp;Chudzicki</a>\n \n<br>\n<br>\nzero point: I do think asking people questions can get at their happiness level, though there is noise.  Answers to \"are you happy\" and similar questions correlates well with other indicators like physical and emotional state.  I think we can start to approximate the zero point by looking at which people want to kill themselves.  It would be helpful (for this purpose of finding the zero) if there were not societal taboos against suicide and people were not encouraged to think of how sad everyone else would be if they were to die.\n<br>\n<br>\nsinger: I don't dispute (1).\n<br>\n<br>\nAs for (2), I'm not sure whether non-human pain is bad.  I think the boundary might be sentience?  If it is bad, I think it's probably much less bad than human pain.</p>", 1314986482], ["Chris", "https://plus.google.com/117346402173047680184", "gp-1314986529473", "<p>This paragraph is counter-factual: If by average you mean the mean, maximizing the total and maximizing the mean is the same. Well, unless you're allowed to kill people to remove them from the equation. In that case, logic says you always want to kill the sad people, and if you're trying to maximize the average, you want to kill all but the happiest.\n<br>\n<br>\nThis is a big part of why I think it's important to not just add up people's happiness to figure out the evaluation function. I don't know what the right way to figure out the evaluation function is. I don't think it's a simple function at all.\n<br>\n<br>\nI think I think about making the universe a better place, but on a day to day basis I also have to make decisions to make myself happy, while still making other people happy too. As a human being, I have limited processing power so cannot figure out exactly what effect my actions will have.\n<br>\n<br>\nThus I form rules to live by. My biggest rule is to not hurt other people. Another is not to lie. I'm learning to make another rule to take care of myself and another is to communicate my emotions whenever possible. Sometimes these rules bump up against one another. When that happens, it's worth spending the extra processing power to consider which way to go about things.</p>", 1314986529], ["Chris", "https://plus.google.com/117346402173047680184", "gp-1314986874477", "<p>Okay, I should have read the whole post before posting myself.  I also think it's important to remember network effects.  If you killed all the sad people, that would almost certainly have an effect of saddening other people.\n<br>\n<br>\nAlso, is freedom more important than happiness?  Is intelligence more important than happiness?  Competence?  Contentment?  Self knowledge?  Happiness today or happiness tomorrow?  Even the evaluation function for a single person is super complicated.</p>", 1314986874], ["Chris", "https://plus.google.com/117346402173047680184", "gp-1314988031383", "<p>I just noticed.  We're coming at this from a very interesting point of view.  We're kinda doing things backward from the logical way.  Instead of picking a basis that we believe in and finding out how it results and living that way, we're trying out different bases and seeing which ones lead to our intuitive beliefs.</p>", 1314988031], ["Jeff&nbsp;Kaufman", "https://plus.google.com/103013777355236494008", "gp-1314988055156", "<p>@<a href=\"https://plus.google.com/117346402173047680184\">Chris</a>\n \" unless you're allowed to kill people to remove them from the equation\" um, sort of?  We have choices that have an effect on what the total number of people will be in the future.  As long as the total number is constant, though, you're right that mean and average maximize the same.</p>", 1314988055], ["Jeff&nbsp;Kaufman", "https://plus.google.com/103013777355236494008", "gp-1314988482753", "<p>@<a href=\"https://plus.google.com/117346402173047680184\">Chris</a>\n \"we're trying out different bases and seeing which ones lead to our intuitive beliefs\".  If that was all we were doing, this would be useless.  But if I start with the beliefs that include \"hurting people is wrong\", \"lying is wrong\", \"causing suffering is wrong\", \"helping people is good\" there will be cases where they conflict (lying to save someone's life, say).  I notice that some form of total utilitarianism does a good job of matching up with my existing moral beliefs but being simpler and much more consistent, so I adopt it.  Before I adopted it I was a pacifist who didn't give much money away.  I now believe, for utilitarian reasons, that those positions were wrong.  Now I am only very much against war, not convinced that war is always wrong.  And I am convinced that I should be earning as much as I can so I can give away as much as I can to effective charities.  So this isn't just an exercise of choosing a base that matches intuitive beliefs.</p>", 1314988482], ["Jeff&nbsp;Kaufman", "https://plus.google.com/103013777355236494008", "gp-1314988628988", "<p>@<a href=\"https://plus.google.com/117346402173047680184\">Chris</a>\n I think happiness includes freedom, etc.  When you don't have freedom, people are less happy.  People have at times thought they could increase happiness by decreasing freedom, but they turned out to be wrong.</p>", 1314988628]]